{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuoraDuplicateQuestions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baahujain/ML/blob/master/QuoraDuplicateQuestions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ9PZGgoGJIG",
        "colab_type": "code",
        "outputId": "3783110f-684a-44d8-9417-0949369400ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkmIEHRXFRuR",
        "colab_type": "code",
        "outputId": "1acd5bb8-b6c9-41f0-911e-beaa9d04b2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Mount in the google drive, in google the training data is placed\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-kHG379GKRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79H4tH4GMxpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ff5ded0f-70e8-4b3e-9f0b-02bdc3ad4721"
      },
      "source": [
        "\n",
        "df.describe()\n",
        "#remove entries which are blank\n",
        "df = df.dropna(subset = ['question1', 'question2'])\n",
        "\n",
        "#Check to see if there is any imbalance between duplicates and non-duplicates in training data\n",
        "plt.bar([\"0\",\"1\"],pd.value_counts(df.dropna()['is_duplicate']))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 2 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI1r4xmue3gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvXDs-nj1SHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "3465d353-169a-49be-c3bd-c90bce23ab89"
      },
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "embed = hub.Module(url)\n",
        "\n",
        "#Get the sentence embedding (universal sentence encoder)\n",
        "def GetEmbedding(x):\n",
        "  return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
        "  #return embed(x, signature=\"default\", as_dict=True)[\"default\"] "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0605 11:57:32.571474 140582367655808 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0605 11:57:33.713819 140582367655808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuDhSL3Bdth-",
        "colab_type": "text"
      },
      "source": [
        "Create a deep learning model. Here functional APIs are used. We have two input layers to take the 2 sentences. For every sentence we retrieve the sentence embedding.\n",
        "The sentence embeddings are concatenated and passed thru 2 layers of dense layers. Last dense layer has a sigmoid activation to determine if the statements are duplicates or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFFDAHHti2A6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cta_3qHkeawX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBnCsKXy16uX",
        "colab_type": "code",
        "outputId": "8ceb5ebc-fca7-4209-f27d-a61863fb5cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "DROP=0.1\n",
        "q1=layers.Input(shape=(1,),dtype=tf.string)\n",
        "embedding_q1 = layers.Lambda(GetEmbedding,output_shape=(512,))(q1)\n",
        "\n",
        "q2=layers.Input(shape=(1,),dtype=tf.string)\n",
        "embedding_q2 = layers.Lambda(GetEmbedding,output_shape=(512,))(q2)\n",
        "\n",
        "x=layers.concatenate([embedding_q1,embedding_q2])\n",
        "x=layers.Dense(200,activation='relu')(x)\n",
        "x=layers.Dropout(0.1)(x)\n",
        "\n",
        "x=layers.Dense(200,activation='relu')(x)\n",
        "x=layers.Dropout(0.1)(x)\n",
        "\n",
        "pred=layers.Dense(2,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=[q1,q2], outputs=pred)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 11:58:56.691562 140582367655808 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 11:58:57.890139 140582367655808 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0605 11:58:58.084727 140582367655808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 512)          0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 512)          0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1024)         0           lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 200)          205000      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 200)          40200       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 200)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            402         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 245,602\n",
            "Trainable params: 245,602\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDq-z9SFCZx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create traning and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X1 = df['question1']\n",
        "X2 = df['question2']\n",
        "y = df['is_duplicate']\n",
        "# Using the sklearn to split data in question1 and question2 train and test in the ration 80-20 %\n",
        "X1_train, X1_test,X2_train, X2_test, y_train, y_test = train_test_split(X1, X2, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_q1 = X1_train.tolist()\n",
        "train_q1 = np.array(train_q1, dtype=object)#[:, np.newaxis]\n",
        "train_q2 = X2_train.tolist()\n",
        "train_q2 = np.array(train_q2, dtype=object)#[:, np.newaxis]\n",
        "\n",
        "train_labels = np.asarray(pd.get_dummies(y_train[:]), dtype = np.int8)\n",
        "\n",
        "test_q1 = X1_test.tolist()\n",
        "test_q1 = np.array(test_q1, dtype=object)#[:, np.newaxis]\n",
        "test_q2 = X2_test.tolist()\n",
        "test_q2 = np.array(test_q2, dtype=object)#[:, np.newaxis]\n",
        "\n",
        "test_labels = np.asarray(pd.get_dummies(y_test[:]), dtype = np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtTXb4KLEuJW",
        "colab_type": "code",
        "outputId": "63f7722b-8c1c-47a4-f9b6-717d83b1dbe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Training\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  \n",
        "  filepath=\"/content/drive/My Drive/Colab Notebooks/quoraDup/model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  history = model.fit([train_q1, train_q2], \n",
        "            train_labels,\n",
        "            validation_data=([test_q1, test_q2], test_labels),\n",
        "            epochs=10,\n",
        "            batch_size=512, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 323429 samples, validate on 80858 samples\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fdb4f62df60>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
            "    self._session._session, self._handle, status)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
            "    c_api.TF_GetCode(self.status.status))\n",
            "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "323072/323429 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.7788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fdb4f4664a8>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
            "    self._session._session, self._handle, status)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
            "    c_api.TF_GetCode(self.status.status))\n",
            "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r323429/323429 [==============================] - 718s 2ms/step - loss: 0.4471 - acc: 0.7789 - val_loss: 0.3888 - val_acc: 0.8130\n",
            "Epoch 2/10\n",
            "323429/323429 [==============================] - 711s 2ms/step - loss: 0.3758 - acc: 0.8221 - val_loss: 0.3662 - val_acc: 0.8266\n",
            "Epoch 3/10\n",
            "323429/323429 [==============================] - 712s 2ms/step - loss: 0.3555 - acc: 0.8335 - val_loss: 0.3575 - val_acc: 0.8317\n",
            "Epoch 4/10\n",
            "323072/323429 [============================>.] - ETA: 0s - loss: 0.3422 - acc: 0.8417"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWlziFYhPvbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# Predict the similarity of questions\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  # Loading the save weights\n",
        "  #Modify this to appropriate location\n",
        "  model.load_weights('/content/drive/My Drive/Colab Notebooks/quoraDup/model-10-0.85.hdf5')  \n",
        "\n",
        "\n",
        "  while 1:\n",
        "  \n",
        "    q1 = input(\"Key in your first question -->\")\n",
        "    q2 = input(\"Key in your second question -->\") \n",
        "    q1 = np.array([[q1],[q1]])\n",
        "    q2 = np.array([[q2],[q2]])\n",
        "    predicts = model.predict([q1, q2], verbose=0)\n",
        "    predict_logits = predicts.argmax(axis=1)\n",
        "    print(\"----FINAL RESULT----\")\n",
        "    if(predict_logits[0] == 1):\n",
        "      print(\"****Questions are Similar****\")\n",
        "    else:\n",
        "      print(\"****Questions are not Similar****\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}